"""
Telegram-–±–æ—Ç —Å OpenAI (gpt-5-mini). –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞–º—è—Ç–∏, —É—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ SQLite.
"""

import asyncio
import logging
import sys

from aiogram import Bot, Dispatcher, F
from aiogram.filters import Command
from aiogram.types import Message

from config import BOT_OPENAI_MODEL, BOT_TOKEN, OPENAI_API_KEY
from context_manager import (
    append_to_context,
    clear_context,
    get_messages,
    get_user_token_stats,
    init_token_usage_db,
    log_token_usage,
)
from openai_client import get_chat_response

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger(__name__)

CLEAR_PHRASES = ("–æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç", "–æ—á–∏—Å—Ç–∏—Ç—å", "clear context", "clear")

# –°—Ç–æ–∏–º–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤: –∑–∞–ø—Ä–æ—Å—ã $0.25 / 1M, –æ—Ç–≤–µ—Ç—ã $2 / 1M
PROMPT_COST_PER_1M = 0.25
COMPLETION_COST_PER_1M = 2.0

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()


def _call_openai(messages: list[dict[str, str]]) -> tuple[str, dict[str, int] | None]:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ OpenAI (–¥–ª—è run_in_executor). –ë–µ–∑ temperature/max_tokens ‚Äî –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π."""
    return get_chat_response(messages, BOT_OPENAI_MODEL)


@dp.message(Command("start"))
async def cmd_start(message: Message) -> None:
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç —Å GPT. –ü–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è ‚Äî —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n"
        "/clear –∏–ª–∏ ¬´–æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç¬ª ‚Äî —Å–±—Ä–æ—Å–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é.\n"
        "/stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å."
    )


@dp.message(Command("stats"))
async def cmd_stats(message: Message) -> None:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö."""
    user_id = message.from_user.id if message.from_user else 0
    prompt_tokens, completion_tokens = get_user_token_stats(user_id)
    cost_prompt = (prompt_tokens / 1_000_000) * PROMPT_COST_PER_1M
    cost_completion = (completion_tokens / 1_000_000) * COMPLETION_COST_PER_1M
    total_cost = cost_prompt + cost_completion
    text = (
        "üìä <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤</b>\n\n"
        f"–¢–æ–∫–µ–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤: <b>{prompt_tokens:,}</b>\n"
        f"–¢–æ–∫–µ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤: <b>{completion_tokens:,}</b>\n"
        f"–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: <b>{prompt_tokens + completion_tokens:,}</b>\n\n"
        "üí∞ <b>–°—Ç–æ–∏–º–æ—Å—Ç—å</b>\n"
        f"–ó–∞–ø—Ä–æ—Å—ã ($0.25/1M): <b>${cost_prompt:.6f}</b>\n"
        f"–û—Ç–≤–µ—Ç—ã ($2/1M): <b>${cost_completion:.6f}</b>\n"
        f"–ò—Ç–æ–≥–æ: <b>${total_cost:.6f}</b>"
    )
    await message.answer(text, parse_mode="HTML")


@dp.message(Command("clear"))
async def cmd_clear(message: Message) -> None:
    user_id = message.from_user.id if message.from_user else 0
    clear_context(user_id)
    await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω. –ú–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –∑–∞–Ω–æ–≤–æ.")


@dp.message(F.text)
async def handle_text(message: Message) -> None:
    if not message.text or not message.from_user:
        return

    user_id = message.from_user.id
    text = message.text.strip()

    if text.lower() in CLEAR_PHRASES or text == "/clear":
        clear_context(user_id)
        await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω. –ú–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –∑–∞–Ω–æ–≤–æ.")
        return

    messages = get_messages(user_id) + [{"role": "user", "content": text}]

    await message.answer("–î—É–º–∞—é‚Ä¶")
    loop = asyncio.get_event_loop()
    try:
        content, usage = await loop.run_in_executor(None, _call_openai, messages)
    except Exception as e:
        logger.exception("OpenAI error for user %s: %s", user_id, e)
        await message.answer(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ —É–ø—Ä–æ—Å—Ç–∏—Ç–µ –∑–∞–ø—Ä–æ—Å."
        )
        return

    append_to_context(user_id, text, content)

    if usage:
        log_token_usage(
            user_id,
            usage["prompt_tokens"],
            usage["completion_tokens"],
            usage["total_tokens"],
        )

    if len(content) > 4000:
        content = content[:3997] + "..."
    await message.answer(content)


async def main() -> None:
    if not BOT_TOKEN:
        logger.error("BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ .env")
        sys.exit(1)
    if not OPENAI_API_KEY:
        logger.error("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ .env")
        sys.exit(1)

    init_token_usage_db()
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω (–º–æ–¥–µ–ª—å: %s)", BOT_OPENAI_MODEL)
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
